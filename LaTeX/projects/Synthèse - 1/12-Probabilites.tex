\chapter*{\chapterstyle{XII --- Espaces probabilisés}} % 75% Fini
\addcontentsline{toc}{section}{Espaces probabilisés}
Le domaine des probabilités chercher à modéliser des \textbf{expériences aléatoires} ie des expériences dont toutes les \textbf{issues} possibles sont connues à priori mais dont le résultat peut varier lorsqu'on la répète (lancer de dés, tirage dans une urne\ldots).\<

Le cadre de la théorie de la mesure, nous permet de formaliser la théorie axiomatique des probabilités, ainsi que les différents objets en jeu, en particulier, on considère un espace mesurable \( ( \Omega, \mathcal{A}) \) muni d'une mesure \( \mathbb{P} \) à valeurs dans \( \icc{0}{1} \) et telle que \( \mathbb{P}( \Omega) = 1 \). On apelle une telle mesure \textbf{loi de probabilité}.\<

Le triplet \( ( \Omega, \mathcal{A}, \mathbb{P}) \) est alors apellé \textbf{espace probabilisé}. Dans ce cadre l'ensemble \( \Omega \) des issues possibles de l'expérience est apellé \textbf{univers}, les parties mesurables sont apellées \textbf{évenements} et deux parties mesurables disjointes seront dites \textbf{incompatibles}.

\subsection*{\subsecstyle{Espace probabilisé discret et continu}}
La mesure de l'espace doit être égale à 1 donc en particulier, on doit avoir \( \int_ \Omega d \mathbb{P} = 1 \), ceci étant dit, on peut alors distinguer deux grands cas d'espaces probabilisés:
\begin{itemize}
   \item Le cas où les parties non-négligeables de \( \Omega \) sont \textbf{dénombrables}, alors par applications de la relation de Chasles et l'invisibilité des parties négligeables, on obtient que:
   \[ 
      \int_\Omega d \mathbb{P} = \int_{\bigcup x_n} d \mathbb{P} = \sum_n \mathbb{P}(x_n)
   \]
   On remarque alors que la loi de probabilité est entièrement déterminée par la probabilité \textbf{d'évenements élémentaires} d'une certaine famille \( (x_n) \) dont la série vaut 1. On appele cette famille \textbf{distribution} de \( \mathbb{P} \) et de tels espaces \textbf{espaces probabilisés discrets}.
   \item Le cas où elles ne le sont pas et que \( \Omega \subseteq \R^n \), alors il est toujours possible de définir la \textbf{fonction de répartition} de la mesure de probabilité par la fonction suivante qui caractérise la loi:
   \[ 
      F : x \longrightarrow \mathbb{P}(\ioc{-\infty}{x})
   \]
   Si de plus les non-boréliens sont négligeables pour \( \mathbb{P} \) (on dit aussi que \( \mathbb{P} \) est \textbf{absolument continue} par rapport à la mesure de Lebesgue) alors on peut montrer que \( \mathbb{P} \) admet une densité, c'est à dire une fonction intégrable \( f \) dont l'intégrale vaut 1 et qui caractérise alors la probabilité:
   \[ 
      \mathbb{P}(A) = \int_A f(x)dx 
   \]
   On dira alors que ces lois sont des \textbf{lois à densité}. Si la dernière condition n'est pas vérifiée, on dira alors que la loi est \textbf{mixte ou singulière}.
\end{itemize}
\subsection*{\subsecstyle{Espace probabilisé produit}}
Si on se donne une famille de \( n \) espaces probabilisés \( ( \Omega_i, \mathscr{A}_i, \mathbb{P}_i) \), on peut alors conformément à la théorie de la mesure définir l'espace produit \( ( \prod \Omega_i, \mathscr{A}_\otimes, \mathbb{P}_\otimes ) \) avec la tribu et la loi produit. Dans tout la suite on considère simplement le cas \( n=2 \) pour simplifier.

Selon le cas discret ou a densité, on a alors que la loi est caractérisée par:
\begin{itemize}
   \item \textbf{Cas dénombrable:}
   \[
      \mathbb{P}_\otimes(A) = \sum_{\N \times \N} \mathbb{P}_\otimes(x_n, y_m)
   \]
   \item \textbf{Cas absolument continu:}
   \[
      \mathbb{P}_\otimes(A) = \int_{\Omega_1 \times \Omega_2} f(x, y) d\mathbb{P}_\otimes
   \]
\end{itemize}
\pagebreak
\subsection*{\subsecstyle{Lois marginales}}
Sachant la loi produit \( \mathbb{P} \), une question intéressante est alors de determiner les lois \textbf{marginales} des espaces composantes, on montre alors qu'on a:
\begin{itemize}
   \item \textbf{Dans le cas dénombrable:}
   \[
      \mathbb{P}_1(\{k\}) = \sum_{\N} \mathbb{P}(\{k\}, y_m)
   \]
   \item \textbf{Dans le cas absolument continu:}
   \[
      f_1(x) = \int_{\Omega_1} f(x, y) dy
   \]
\end{itemize}
Malheureusement on peut montrer que la donnée des lois marginales ne caractérise pas la loi produit, en effet les lois marginales dans le cas fini par exemple correspondent aux sommes des lignes ou colonnes du tableau des probabilités et deux sommes peuvent être égales sans que les valeurs individuelles soient toutes égales.
\subsection*{\subsecstyle{Exemples}}
Plusieurs exemples de différentes natures:
\begin{itemize}
   \item \textbf{Discret fini:} Si on cherche à modéliser 3 tirages successifs à pile ou face avec une pièce non truquée, on peut modéliser cette expérience par l'espace probabilisé suivant:
   \[ 
      \left(\left\{ (r_1, r_2, r_3) \; ; \; (r_i) \in \{P, F\}\right\}, \mathcal{P}( \Omega), \mathbb{P}(A) = \frac{|A|}{| \Omega|} \right)
   \]
   \item  \textbf{Discret infini:} Si on cherche à modéliser le nombres de visiteurs qui se présentent dans un musée, on peut alors modéliser ce phénomène par un espace probabilisé dénombrable et une probabilité rapidement décroissante, ie on pose par exemple:
   \[ 
      \left(\N, \mathcal{P}( \N), \mathbb{P}(\{n\}) = \frac{1}{2^{n+1}  } \right)
   \]
   Alors ceci est bien un espace probabilisé discret infini.
   \item \textbf{Absolument continu:} Si on cherche à modéliser un tir de fléchette sur le disque unité \( D \subseteq \R^2 \)où la probabilité suit une densité uniforme, alors on peut poser:
   \[ 
      \left( D, \mathcal{B}(D), \mathbb{P}(D) = \frac{1}{ \pi}\int_A d \mu = \frac{ \mu(A)}{ \pi}\right)
   \]
   \item \textbf{Mixte:} Si on cherche à modéliser une loterie où l'on tire un nombre de \( \icc{0}{10} \) avec \( \mathbb{P}(\{0\}) = 0.1 \) qui correspond au jackpot et densité uniforme pour le reste des nombres. Alors on a naturellement une structure d'espace probabilisé mixte.
   \item \textbf{Espace produit:} Si on cherche à modéliser le choix uniforme d'un point dans \( \inticc{1}{n}^2 \), on modèlise ceci par l'espace produit:
   \[ 
      (\inticc{1}{n}^2, \mathcal{P}(\inticc{1}{n}^2), \mathbb{P}(\{(k, l)\}) = \frac{1}{n^2}) 
   \]
   Alors les distributions marginales sont facilement \( \mathbb{P}_1(\{k\}) = \mathbb{P}_2(\{k\}) = \frac{1}{n} \), on a en fait le tableau des probabilités décrit par la matrice de taille \( n \) suivante:
   \[ 
      \begin{pmatrix}                   
         \frac{1}{n^2} & \ldots & \frac{1}{n^2}\\
         \vdots & \ddots & \vdots\\
         \frac{1}{n^2} & \ldots & \frac{1}{n^2}
      \end{pmatrix}
   \]
   Les colonnes (resp. lignes) correspondant aux probabilités \( \mathbb{P}_1(\{k\}) \) (resp. \( \mathbb{P}_2(\{k\}) \))
\end{itemize}
\chapter*{\chapterstyle{XII --- Probabilités conditionnelles}} % 75% Fini
Lorsque l'on dispose d'informations sur le résultat d'une expérience donnée, il est possible d'affiner nos
prédictions. \+
Soit \(X\) un évenement qui n'est pas négligeable, alors on définit l'application:
\[
   \begin{aligned}
      \mathbb{P}( \cdot | X): \Pow(\Omega) &\longrightarrow \icc{0}{1}\\
      A &\longmapsto \frac{\mathbb{P}(A \cap X)}{\mathbb{P}(X)}
   \end{aligned}
\]
On peut montrer que c'est une mesure de probabilité sur \(\Omega\) et on l'appelle \textbf{probabilité de A sachant X}. De la symétrie de l'intersection on peut alors en déduire la \textbf{formule de Bayes} qui permet alors \textbf{d'inverser le conditionnement}:
\[
   \mathbb{P}(A | B) = \frac{\mathbb{P}(A) \mathbb{P}(B | A)}{\mathbb{P}(B)}
\]
\subsection*{\subsecstyle{Formule des probabilités composées}}
On en déduit directement la \textbf{formule des probabilités composées}:
\[
      \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B | A) = \mathbb{P}(B)\mathbb{P}(A | B)
\]

Qui se généralise pour une famille finie d'évenements \((A_n)_{n \in I}\) d'intersection non nulle:
\[
   \mathbb{P}(A_1 \cap \ldots \cap A_n) = \mathbb{P}(A_1)\mathbb{P}_{A_1}(A_2)\mathbb{P}_{A_1\cap A_2}(A_3)\ldots\mathbb{P}_{A_1\cap \ldots \cap A_{n-1}}(A_n)
\]
\subsection*{\subsecstyle{Formule des probabilités totales}}
On considère une partition \((A_n)_n\) de \( \Omega \) en évenements disjoints (on appelle une telle partition \textbf{systême complet d'évenements}), alors on peut montrer la \textbf{formule des probabilités totales}:
\[
   \mathbb{P}(B) = \sum_{k=1}^{n} \mathbb{P}(A_k) \mathbb{P}_{A_k}(B)
\]
\subsection*{\subsecstyle{Indépendance}}
On dit que deux évenements \(A, B\) sont \textbf{indépendants} si et seulement si la donnée de la réalisation d'un des évenements n'influence pas l'autre, ie:
\[ 
   \mathbb{P}(A | B) = \mathbb{P}(A)  
\]
Ou encore par la formule conditionelle:
\[
      \mathbb{P}(A \cap B) = \mathbb{P}(A)\mathbb{P}(B)
\]
Si deux évenements sont indépendants, alors n'importe quelle paire de \(A, B, \overline{A}, \overline{B}\) est indépendante.
\chapter*{\chapterstyle{XII --- Lois usuelles}} % 75% Fini
Dans ce chapitre, on énumère les lois usuelles en probabilité et leurs cas d'utilisation. Comme vu précédement, on distingue le cas discret et absolument continu. Dans tout la suite on considère un espace probabilisé \( ( \Omega, \mathscr{A}, \mathbb{P}) \).

\subsection*{\subsecstyle{Lois discretes usuelles}}
On appelle \textbf{épreuve de Bernoulli} est une expérience aléatoire qui n'a que deux issues, usuellement nommées \textbf{succés et échec}.\<

On dit que la loi est \textbf{uniforme} si on a la distribution:
\[
   \forall A \in \mathscr{A} \; ; \; \mathbb{P}(A) = \frac{|A|}{|E|}  
\]
On dit que la loi est \textbf{binomiale} de paramêtres \(n, p\) si \( \Omega = \{1, \ldots, n\}\) et si on a la distribution:
\[
   \forall k \leq n \; ; \; \mathbb{P}(\{k\}) = \binom{n}{k} \; p^k(1-p)^{n-k}
\]
On dit que la loi est \textbf{géométrique} de paramêtre \( p \) si \(\Omega = \N^*\) et si on a la distribution:
\[
   \forall k \geq 1 \; ; \;  \mathbb{P}(\{k\}) = p(1 - p)^{k - 1}
\]
On dit que la loi est \textbf{hypergéométrique} de paramêtres \((p, n, N)\) si \(\Omega = \N^*\) et si on a la distribution:
\[
   \forall k \geq 1 \; ; \; \mathbb{P}(\{k\}) = \frac{\binom{pN}{k}\binom{(1-p)N}{n - k}}{\binom{N}{n}}
\]
On dit que la loi est \textbf{de Poisson} de paramêtres \( \lambda\) si \(\Omega = \N^*\) et si on a la distribution:
\[
   \forall k \geq 1 \; ; \; \mathbb{P}(\{k\}) = \frac{\lambda^k}{k!}e^{-\lambda}
\]\<

La \textbf{loi binomiale} est utilisée pour déterminer la probabilité d'obtenir exactement \(k\) succés aprés \(n\) itérations d'une épreuve de Bernoulli. \+
La \textbf{loi géométrique} est utilisée pour déterminer la probabilité d'un temps d'attente \( k \) avant le le premier succés d'une épreuve de Bernoulli.\+
La \textbf{loi hypergéométrique} est utilisée pour déterminer la probabilité d'obtenir \(k\) succés aprés \(n\) itérations d'une épreuve de tirage sans remise dans une urne contenant \(N\) boules, dont \(pN\) boules gagantes, et \((1-p)N\) boules perdantes, avec la contrainte que \(pN\) soit un entier.\+
La \textbf{loi de Poisson} est utilisée pour déterminer le nombre d'événements se produisant dans un intervalle de temps fixé, si ces événements se produisent avec une fréquence moyenne connue, et indépendamment du temps écoulé depuis l'événement précédent\footnote[1]{C'est une loi qui s'obtient asymptotiquement à partir d'une loi binomiale de paramêtres \(T, \frac{\lambda}{T}\) en faisant tendre \(T\) vers l'infini.}.

\pagebreak
\subsection*{\subsecstyle{Lois à densité usuelles}}

On dit que la loi est \textbf{uniforme} si sa densité \(f\) est constante sur un intervalle \(\icc{a}{b}\) et nulle en dehors.\+
On dit que la loi est \textbf{exponentielle} de paramètre \(\lambda\) si on a la densité:
\[
   f(x) = \lambda\exp{(-\lambda x)} \; ; \; x \geq 0  
\]
On dit que la loi est \textbf{normale} dee paramêtres\footnote[1]{Ces paramêtres correspondent alors à l'éspérance et l'écart type de la loi.} \(\mu, \sigma\) si on a la densité:
\[
   f(x) = \frac{1}{\sigma\sqrt{2\pi}} \exp{\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)}
\]

La \textbf{loi exponentielle} est utilisée pour modéliser le temps d'attente d'un phénomène sans mémoire, en particulier, c'est l'analogue continue de la loi géométrique\footnote[2]{Elle s'obtient asymptotiquement à partir d'une loi géométrique de paramètre \(\lambda T\) en faisant tendre \(T\) vers 0.}. \+
La \textbf{loi normale} est fondamentale en probabilités du fait de son omniprésence dans les sciences expérimentales, en effet, un théorème fondamental montrera que la somme d'une suite de variables aléatoires (comprendre expériences) convergera vers une certaine loi normale. Elle est donc d'importance capitale en statistiques.\+
\chapter*{\chapterstyle{XII --- Variables aléatoires}} % 95% Fini
\addcontentsline{toc}{section}{Variables aléatoires}
Trés souvent, il se trouve que l'espace probabilisé de l'expérience est inconnu, trop grand ou trop complexe, on considérera alors simplement son existence et on étudiera celui ci via des fonctions définies sur cet espace, appelées \textbf{variables aléatoires}. Ces fonctions induiront un nouvel espace probabilisé correspondant à notre expérience précise (souvent un espace probabilisé numérique). \<

On considère alors souvent \( ( \Omega, \mathscr{A}, \mathbb{P}) \) comme un espace probabilisé abstrait et on l'oublie même complétement trés souvent. Par exemple:
\begin{itemize}
   \item On considère une expérience aléatoire qui tire au hasard un gateau dans une chaîne de fabrication, on peut alors définir une variable aléatoire sur l'espace probabilisé naturellement défini qui à chaque évenement associe le volume du gateau, son taux de sucre, le nombre de raisins secs ... Et faire alors des suppositions sur la loi de ces variables aléatoires par exemple on pourra supposer que le taux de sucre d'un gateau choisi au hasard suit une loi normale.
   \item Si on considère un groupe de \( N \) personnes vivant un épisode épidémique, alors il est trés compliqué de modéliser l'état épidémique du groupe à un instant donné du fait des différentes intéractions et dépendances, on préfère alors éudier des espaces probabilisés plus simples induits par des variables aléatoires comme le nombre de personnes infectées, le temps mis par l'épidémie pour atteindre une certaine taille etc ..
\end{itemize}
\subsection*{\subsecstyle{Définition}}
On dira que \( X \) est une \textbf{variable aléatoire} de \( ( \Omega_1, \mathscr{A}, \mathbb{P}) \) vers un espace mesurable \( ( \Omega_2, \mathscr{B}) \) si et seulement si c'est une \textbf{fonction mesurable} sur cet espace. Elle définit alors une loi naturelle sur \( \Omega_2 \) définie par la \textbf{mesure image}:
\[
   \begin{aligned}
      \mathbb{P}_X: \mathscr{B} &\longrightarrow \icc{0}{1}\\
      B &\longmapsto \mathbb{P}(X^{-1}(B))
   \end{aligned}
\]
On note alors plus simplement \( \mathbb{P}_X(B) = \mathbb{P}(X \in B) \). Trés souvent, on considérera \( (\R^n, \mathcal{B}( \R^n)) \) comme espace d'arrivée et donc la variable aléatoire sera dite \textbf{réelle} et définira une loi sur les boréliens.
\subsection*{\subsecstyle{Cas réel}}
Dans le cas de variables aléatoires \textbf{réelles} on peut aussi créer une notation qui s'applique si \(B\) est un intervalle et on a:
\[
   X^{-1}\bigl(\ioo{a}{b}\bigl) = \Bigl\{ \omega \in \Omega \; ; \;  a < X(\omega) < b\Bigl\} \notationEq (a < X < b)
\]
\subsection*{\subsecstyle{Propriétés}}
La famille \(((X = a))_{a \in X(\Omega)}\) est un \textbf{système complet d'évenements}, en effet car si on considère une issue \(\omega \in \Omega\), on a:
\[
   \begin{cases}
      X(\omega) = x \implies \omega \in (X = x)\\  
      X(\omega) \neq x \implies \omega \notin (X = x)   
   \end{cases} 
\]
\begin{center}
   \textit{On peut donc partitionner les éléments de \(\Omega\) selon leur image par \(X\)}
\end{center}
On peut aussi noter que si \(f\) est une application mesurable, alors \(f \circ X\) \textbf{est une variable aléatoire} sur les espaces correspondants.
\pagebreak
\subsection*{\subsecstyle{Indépendance}}
On dira alors que deux variables aléatoires \(X, Y\) sont indépendantes si et seulement si pour tout couple \(x, y\), les évenements correspondants sont indépendants:
\[
   \mathbb{P}(X = x \cap Y = y) = \mathbb{P}(X = x)\mathbb{P}(Y = y)  
\]
Par ailleurs, si \(X, Y\) sont deux variables aléatoires, il existe une mesure de la dépendance (corrélation) de deux variables aléatoires appellée \textbf{covariance} définie dans la dernière partie.
\subsection*{\subsecstyle{Cas des vecteurs aléatoires}}
Dans le cas où la variable aléatoire \( X = (X_1, \ldots, X_n) \) est à valeurs dans \( \R^n \), alors elle définit une loi produit (appelée dans ce cadre \textbf{loi conjointe} de \( X \)) sur les boréliens et on l'appelle \textbf{vecteur aléatoire}. En particulier les lois marginales sont alors les lois des variables composantes \( X_i \). Par exemple si on prends un vecteur aléatoire choisissant uniformément un point dans \( \inticc{1}{n}^2 \), alors on a que:
\[ 
   \mathbb{P}(X = (k, l)) = \frac{1}{n^2} 
\]
Et les loi marginales sont données par:
\[ 
   \mathbb{P}(X_1 = k) = \sum_{i=1}^n \mathbb{P}(X = (k, i))  
\]
On retrouve alors les même lois marginales que dans l'exemple analogue sans variable aléatoire, en particulier les lois conjointe et marginales sont exactement les lois produits et marginales sur \(\R \times \R\).   
\subsection*{\subsecstyle{Intégrabilité et formule de transfert}}
On se donne une variable aléatoire réelle intégrable par rapport à la mesure \( \mathbb{P} \) ie telle que:
\[ 
   \int_\Omega X( \omega)d \mathbb{P} < \infty 
\] 
Alors on peut montrer l'identité suivante par les propriétés de la mesure image \( d \mathbb{P}_X \):
\[ 
   \int_\Omega X( \omega) d \mathbb{P} = \int_{\R} xd \mathbb{P}_X
\]
Et même plus généralement, on a le \textbf{théorème de transfert} pour tout fonction \( \phi \) telle qu'une des intégrale ait un sens:
\[ 
   \int_\Omega \phi(X( \omega)) d \mathbb{P} = \int_{\R} \phi(x)d \mathbb{P}_X
\]
Et les intégrales du membre de droite se calculent souvent facilement, par exemple dans les deux cas classiques:
\begin{itemize}
   \item \textbf{Cas dénombrable:} On a 
   \[ 
      \int_{\R} xd \mathbb{P}_X = \sum_\N \int_{y_n} xd \mathbb{P}_X = \sum_\N y_n \mathbb{P}(X = y_n)
   \]
   \item \textbf{Cas absolument continu:} On a 
   \[ 
      \int_{\R} xd \mathbb{P}_X = \int_{\R}xf(x)dx  
   \]
\end{itemize}
\chapter*{\chapterstyle{XII --- Indicateurs}} % 80% Fini
\addcontentsline{toc}{section}{Indicateurs}
Dans tout la suite, on considère \((\Omega, \Pow(\Omega), \mathbb{P})\) un espace probabilisé fini et \(X, Y\) deux variables aléatoires \textbf{intégrables} pour la mesure \( \mathbb{P} \). \<

On appelle \textbf{indicateur de position} un nombre réel permettant de situer les valeurs d'une série statistique, par exemple l'esperance et la médiane sont des indicateurs de position.\+

On appelle \textbf{indicateur de dispersion} un nombre réel permettant de mesurer la variabilité des valeurs d'une série statistique autour d'une valeur (généralement autour de la moyenne), par exemple la variance, l'écart-type ou l'écart interquartile sont des indicateurs de dispersion.

\subsection*{\subsecstyle{Esperance}}
L'espérance mathématique correspond à la moyenne théorique du résultat qu'on peut espérer avoir en répétant une expérience aléatoire un grand nombre de fois, c'est \textbf{la moyenne des valeurs de la variable aléatoire, pondérées par leur probabilités respectives}, ou c'est aussi le centre de masse de la densité, on définit alors celle ci par:
\[
   \expectancy{X} := \int_\Omega X d\mathbb{P}
\]

L'esperance prends alors la forme d'une somme pondérée dans le cas discret, ou d'une intégrale pondéree dans le cas absolument continue. Elle existe toujours dans le cas d'une variable aléatoire \textbf{finie} mais ce n'est pas le cas en général, et il faut alors étudier l'intégrabilité de la variable aléatoire. \<

L'espérance possède plusieurs propriétés remarquables, elle est \textbf{linéaire et croissante} et l'espérance d'une constante est cette constante.\+
Mais en général, l'espérance \textbf{n'est pas multiplicative}, c'est néanmoins le cas quand les deux variables aléatoires sont \textbf{indépendantes}.
\subsection*{\subsecstyle{Variables centrées}}
On rappelle qu'on a le théorème de transfert donc \(\expectancy{\phi(X)}\) existe si \( \phi(X) \) est intégrable. Aussi, on appelle \textbf{variable centrée} une variable aléatoire d'espérance nulle. On peut alors centrer une variable aléatoire par la translation \(X' = X - \expectancy{X}\).
\subsection*{\subsecstyle{Moments d'ordre k}}
On généralise cette définition et on définit le \textbf{moment d'ordre k} de la variable \( X \), si il existe par la quantité suivante:
\[ 
   m_k(X) = \expectancy{X^k} 
\]
On remarque alors que cette quantité existe si et seulement si \( X^k \) est intégrable. De manière générale, on comprends facilement qu'on a la propriété suivante (où la disjonction dépends de la discrétude ou non de \( X \)):
\[ 
   X \text{ admet un moment d'ordre \( k \)} \iff X \in L^k( \Omega) \text{ ou } \ell^k( \Omega)
\]
\subsection*{\subsecstyle{Variance}}
On manque alors d'informations sur les valeurs de \(X\), elles peuvent tout aussi bien rester toujours très
proches de \(\expectancy{X}\), ou s'en éloigner beaucoup, on a donc besoin de mesurer la distance moyenne entre \(X\) et \(\expectancy{X}\), qui serait alors \(\expectancy{| X - \expectancy{X} |}\).\pagebreak

Cette formule est techniquement impraticable du fait de la valeur absolue, on utile donc \textbf{la moyenne des carrés des distances} entre \(X\) et \(\expectancy{X}\), et on définit alors la variance:
\[ 
   \variance{X} := \expectancy{(X - \expectancy{X})^2} = \expectancy{X^2} - \expectancy{X}^2
\]


La deuxième expression apellée \textbf{formule de Koenig-Huygens} se déduit facilement de la première par les propriétés de l'espérance et on en déduit qu'une variable aléatoire admet une variance si et seulement si elle admet un moment d'ordre 2.

On voit directement que la variance est \textbf{positive} (ou nulle si \(X\) est constante presque partout). Elle vérifie aussi les propriétés suivantes:
\begin{itemize}
   \item \textbf{Invariante par translation} \( \variance{X + a} = \variance{X} \)
   \item \textbf{Quadratique}  \( \variance{ \lambda X} = \lambda^2\variance{X} \)
\end{itemize}
\subsection*{\subsecstyle{Ecart type}}
On peut alors définir \textbf{l'écart-type} de la variable \(X\) qui est défini par \(\sigma(X) = \sqrt{\variance{X}}\)\<

Enfin, on appelle \textbf{variable réduite} une variable aléatoire d'écart type \(1\) et on peut alors définir la \textbf{variable centrée réduite} associée à \(X\):
\[
   X^*= \frac{X - \expectancy{X}}{\sigma(X)}  
\]
\subsection*{\subsecstyle{Covariance}}
Dans le cas d'un couple aléatoire et contrairement à l'espérance, le concept de variance perds son sens. Plutôt que de chercher un écart par rapport à la moyenne, on va préférer chercher \textbf{un écart moyen entre les deux variables}\footnote[1]{On remarque que la variance n'est alors que la covariance de \(X\) avec elle-même. Aussi si les deux variables aléatoires sont indépendantes, dans ce cas l'espérance est multiplicative et on a \(\text{Cov}(X, Y) = 0\), la reciproque étant \textbf{fausse}.} qui se définit par:
\[
   \text{Cov}(X, Y) = \mathbb{E}\bigl[(X - \mathbb{E}(X))(Y - \mathbb{E}(Y))\bigl] = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y) 
\]
Gràce à la covariance on peut aussi définir la variance d'une somme:
\[ 
   \variance{X + Y} =   \variance{X} + \variance{Y} +  2\text{Cov}(X, Y)
\]
La covariance de \( X, Y \) n'existe bien sûr que si \( X, Y \) et \( XY \) sont intégrables. 
\subsection*{\subsecstyle{Propriétés de la covariance}}
La covariance vérifie plusieurs propriétés intéressantes:
\begin{itemize}
   \item Si les deux variables aléatoires sont indépendantes, alors on a \(\text{Cov}(X, Y) = 0\), la reciproque étant \textbf{fausse}.
   \item Si \( X \) admet une variance alors on retrouve celle ci comme \( \text{Cov}(X, X) \)
\end{itemize}

On peut même montrer que la covariance est \textbf{bilinéaire, symétrique et positive}. Informellement c'est un \textit{``pseudo produit scalaire''} sur les variables aléatoires, néanmoins suffisament proche du produit scalaire pour avoir \textbf{l'inégalité de Cauchy-Schwartz}:
\begin{align*}
   |\text{Cov}(X, Y)| \leq \sigma(X)\sigma(Y)
\end{align*}
Plus précisément, considérons l'espace des variables aléatoires centrées réduites, alors c'est \textbf{un espace prehilbertien}, et la covariance définit son produit scalaire, l'écart type définit alors la \textbf{norme} associée et on peut définir le coefficient de corrélaition linéaire par:
\[
   \rho_{X, Y} = \frac{\text{Cov}(X, Y)}{\sigma(X)\sigma(Y)}
\]
Qui s'intérpréterait alors comme \textit{l'angle} entre les variable aléatoires.
\pagebreak
\subsection*{\subsecstyle{Espérance \& variances usuelles}}
Il est intéressant de considérer les différents indicateurs de position et de dispersion des lois usuelles\footnote[1]{Pour la loi uniforme on considère \(X\) à valeurs dans \(\inticc{1}{n}\)}

\begin{center}
   \renewcommand{\arraystretch}{2}
   \setlength{\tabcolsep}{18pt}
   
   \begin{tabular}{|c||c|c|}
      \hline
      Lois & \cellcolor{BrightBlue1!40} Espérance & \cellcolor{BrightBlue1!40} Variance \\ 
      \hline
      \cellcolor{BrightBlue1!40} \(X \sim \mathcal{U}(E)\) & \(\frac{n+1}{2}\) & \(\frac{n^2 - 1}{12}\) \\ 
      \hline
      \cellcolor{BrightBlue1!40} \(X \sim \mathcal{B}(n, p)\) & \(n\cdot p\) &  \(n\cdot p(1-p)\) \\ 
      \hline
      \cellcolor{BrightBlue1!40} \(X \sim \mathcal{G}(p)\) & \(\frac{1}{p}\) & \(\frac{1-p}{p^2}\) \\ 
      \hline
      \cellcolor{BrightBlue1!40} \(X \sim \mathcal{H}(p, n, N)\) & \(n\cdot p\) & \(n\cdot p(1-p)\frac{N - n}{N - 1}\) \\ 
      \hline
   \end{tabular}
\end{center}

\subsection*{\subsecstyle{Inégalités}}
On souhaite majorer la probabilité d'avoir des valeurs "extrèmes", ie éloignées de l'espérance, alors si \(X\) est une variable aléatoire positive presque partout et \(\alpha \in \R^{+*}\) on peut montrer \textbf{l'inégalité de Markov}:
\[
   \mathbb{P}(X \geq \alpha) \leq \frac{\expectancy{X}}{\alpha}
\]
Si la variable aléatoire admet une variance, on a alors \textbf{l'inégalité de Bienaymé-Tchebychev}:
\[
   \mathbb{P}(|X - \expectancy{X}| \geq \alpha) \leq \frac{\variance{X}}{\alpha^2}
\]
Cette dernière est un cas particulier de la première mais est en général \textit{plus fine} que la majoration donnée par l'inégalité de Markov.
\chapter*{\chapterstyle{XII --- Convergences Stochastiques}} % 25% Fini
\addcontentsline{toc}{section}{Convergences Stochastiques}
On peut alors tenter d'appliquer les résultat sur les espaces \( L^p \) à la théorie des probabilité, en particulier étudier des intégrales de variables aléatoires, des espérances, etc .. revient à étudier la finitude d'un norme dans \(L^p(\Omega)\) en particulier pour tout \( p \in \icc{1}{\infty} \), on en déduis que les normes \( p \) s'appliquent aux variables aléatoires, ie on a:
\[ 
   \begin{cases}
      \vectNorm{X}_p := \left(\int_\Omega |X|^p d \mathbb{P} \right)^{ \frac{1}{p}} = \left( \expectancy{|X|^p} \right)^{ \frac{1}{p}}\\
      \vectNorm{X}_\infty := \sup\text{ess} \{ |X| \}

   \end{cases}
\]
Où ici \( X \) est supposée à densité ou à distribution \( f(x) \).\<

Cette approche sera alors trés fructueuse, en effet par l'étude et la définition de différent \textit{modes de convergences} bien choisis sur des suites de variables aléatoires \( (X_n) \), on pourra alors démontrer les grands théorèmes probabilistes.
\subsection*{\subsecstyle{Convergence en loi}}
On dira que \(X_n\) \textbf{converge en loi} vers \(X\) si et seulement si pour tout \(x \in \R\), la loi de \( X_n \) est abitrairement proche de la loi de \( X \), ie si on a:
\[
   \mathbb{P}(X_n \leq x) \longrightarrow \mathbb{P}(X \leq x)
\]
On notera alors:
\[
   (X_n) \overset{\mathcal{L}}{\longrightarrow} X
\]
\subsection*{\subsecstyle{Convergence en probabilité}}
On dira que \(X_n\) \textbf{converge en probabilité} vers \(X\) si et seulement si pour tout \(\epsilon > 0\), la probabilité que \( (X_n)_n \) s'éloigne de \( X \) tends vers 0, ie si on a:
\[
   \mathbb{P}(|X_n - X| > \epsilon) \longrightarrow 0
\]
On notera alors:
\[
   (X_n) \overset{\mathcal{P}}{\longrightarrow} X
\]
\subsection*{\subsecstyle{Convergence presque partout}}
On dira que \(X_n\) \textbf{converge presque partout} vers \(X\) si et seulement si elle converge sauf sur un domaine de mesure nul, ie:
\[
   \mathbb{P}\left( \left\{ \omega \in \Omega \; ; \; \lim_{n \rightarrow +\infty} X_n(\omega) \neq X(\omega) \right\}\right) = 0
\]
On notera alors:
\[
   (X_n) \longrightarrow X \; p.p.
\]
\subsection*{\subsecstyle{Convergence $L^p$}}
On dira qu'une suite \( (X_n) \) converge en norme p vers une variable aléatoire \( X \) si et seulement si:
\[ 
   \lim_{n \rightarrow \infty} \vectNorm{X_n - X}_p = \lim_{n \rightarrow \infty} \left(\expectancy{|X_n - X|^p}\right)^{ \frac{1}{p}} =  0 
\]
\subsection*{\subsecstyle{Relations entre les convergences}}
On peut montrer les différentes implications suivantes:
\[ 
   \textbf{Convergence p.p.} \implies \textbf{ Convergence en probabilité } \implies \textbf{Convergence en loi}
\]
Et pour \( p > q \geq 1 \)
\[ 
   \textbf{Convergence }L^p \implies \textbf{Convergence } L^q \implies \textbf{Convergence en probabilité}
\]
\chapter*{\chapterstyle{XII --- Théorèmes limites}} % 25% Fini
\addcontentsline{toc}{section}{Théorèmes limites}

Munis de nos nouveaux outils et modes de convergences des suites de variables aléatoires, on peut alors énoncer et démontrer les grands théorèmes probabilistes.
\subsection*{\subsecstyle{Lois des grands nombres}}
On se donne une suite de variables aléatoires indépendantes et identiquement distribuées (communément noté iid) \((X_n)\) admettant une espérance \(\mu\), et on pose une variable aléatoire appellée \textbf{moyenne\footnote[1]{Elle correspond à la moyenne faite sur les réalisations d'une expérience par exemple.} empirique}:
\[
   \overline{X}_n = \frac{1}{n}\sum_{k=1}^{n}X_k   
\]
Alors on peut montrer la loi \textbf{faible} des grands nombre, ie:
\[
   \overline{X}_n \overset{\mathcal{P}}{\longrightarrow} \mu
\]
Pour les memes hypothèses que précédemment la loi \textbf{forte} des grands nombres nous assure une convergence plus forte, ie on a:
\[
   \overline{X}_n \overset{p.s.}{\longrightarrow} \mu
\]
\subsection*{\subsecstyle{Théorème central limite}}
On se donne une suite de variables aléatoires iid \((X_n)\) admettant une espérance \(\mu\) et un écart-type \(\sigma\) finis, alors on considère à nouveau la moyenne empirique:
\[
   \overline{X}_n = \frac{1}{n}\sum_{k=1}^{n}X_k   
\]
Mais cette fois on considère cette variable sous sa forme \textbf{centrée réduite}, qu'on notera \(\overline{X}_n^*\), alors le théorème central limite nous donne que:
\[
   \overline{X}_n^* \overset{\mathcal{L}}{\longrightarrow} \mathcal{N}(0, 1)
\]