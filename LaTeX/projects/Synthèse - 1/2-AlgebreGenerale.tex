\chapter*{\chapterstyle{II --- Introduction}}
\addcontentsline{toc}{section}{Introduction}

On appelle \textbf{structure algébrique} un ensemble muni d'une (ou plusieurs) opérations appelées \textbf{lois}, c'est l'étude de telles structures mathématiques, des relations entre celles-ci (que nous appeleront morphismes), et de leurs propriétés que nous appeleront \textbf{algèbre générale}.\<

Soit \(E\) un ensemble non-vide, on appelle \textbf{loi de composition interne} une opération binaire sur les éléments de \(E\) (qu'on notera temporairement \(\star\)) telle que:
\[ 
   \forall a, b \in M \; ; \; a \star b \in E
\]
Soit \(K\) un ensemble non-vide, on appelle \textbf{loi de composition externe} une opération binaire entre un élément de \(K\) et un élément de \(E\) (qu'on notera temporairement \(\cdot\)) telle que:
\[ 
   \forall \lambda, a \in K \times E \; ; \; \lambda \cdot a \in E
\]
Soit \( a \in E \), alors on peut aussi rencontrer dans les structures usuelles des éléments remarquables qui peuvent exister ou non:
\begin{itemize}
   \item On dira que \( e \in E \) est un \textbf{élément neutre} pour la loi si \( \forall a \in E \; ; \; a \star e = e \star a = a \)
   \item On dira que \( a^{-1} \in E \) est \textbf{l'inverse} de \( a \) pour la loi si \(a^{-1} \star a = a \star a^{-1} = e\)
\end{itemize}
Ces éléments, si ils existent, sont alors \textbf{uniques}.
\subsection*{\subsecstyle{Monoides {:}}}
Soit \(M\) un ensemble qu'on munit d'une \textbf{loi de composition interne}, alors le couple \((M, \star)\) est appelé un \textbf{magma}, c'est la structure algébrique primitive la plus faible, en effet la seule contrainte étant que la loi soit interne.\<

On peut alors enrichir la structure de magma par les deux contraintes supplémentaires suivantes:
\begin{itemize}
   \item La loi est \textbf{associative}.
   \item Il existe \textbf{un élément neutre} pour la loi.
\end{itemize}
Cette structure plus riche, qu'on appelle \textbf{monoide} nous permet alors d'identifier des exemples remarquables:
\begin{itemize}[itemsep=0pt]
   \item Les entiers naturels munis de l'addition forment un monoide.
   \item L'ensemble des chaines de caractères muni de la concaténation forme un monoide.
\end{itemize}
Les éléments neutres respectifs de ces exemples sont \(0_\N\) et la chaine de caractère vide.
\subsection*{\subsecstyle{Sous-structures {:}}}
Une fois une structure algébrique définie sur \(E\), on peut alors s'intéresser aux parties de \(E\) qui conservent cette structure, on les appellera alors \textbf{sous-structures} de \(E\).\<

En particulier, on dira que \(F\) est une \textbf{sous-structure} de \(E\) (et on notera \(F < E\)) si elle vérifie:
\begin{itemize}
   \item La partie \(F\) est stable par les lois.
   \item Les éléments neutres\footnote[1]{\textbf{Si la structure impose leur existence}} appartient à \(F\) 
   \item Les inverses\footnote[2]{\textbf{Si la structure impose leur existence}} des éléments de \(F\) appartient à \(F\)
\end{itemize}
On montre alors facilement que \textbf{l'intersection} de deux sous-structures est aussi une sous-structure mais que l'union de deux sous-structures n'est en général pas une sous-structure.
\subsection*{\subsecstyle{Sous-structure engendrée {:}}}
On se donne une partie \( A \) de \( E \), on peut alors définir la \textbf{sous-structure engendrée} par \( A \). Si on considère \( (V_i)_{i \in I} \) la famille des sous-structures de \( E \) qui contiennent \( A \), alors on pose:
\[ 
   \left\langle A \right\rangle = \bigcap_{i \in I} V_i
\]
C'est alors clair que c'est la plus petite sous-structure (pour l'inclusion) qui contienne \( A \) et on peut alors la caractériser par la propriété suivante:
\begin{center}
   \textbf{C'est l'ensemble des combinaisons finies obtenues par applications des lois sur des éléments de \( A \).}
\end{center}
\subsection*{\subsecstyle{Morphismes {:}}}
Soit \((E, \star)\) et \((F, \cdot)\)  deux ensembles munis de la meme structure\footnote[1]{Si les structures présentent plusieurs lois, alors les morphismes doivent vérifier la compatibilité pour \textbf{toutes les lois}. Aussi dans le cas particulier de structures qui requièrent l'existence d'un élément neutre, l'image de l'élement neutre de la structure de départ doit être celui de celle d'arrivée.} et \(\varphi: M \rightarrow N\), alors \(\varphi\) est appelé \textbf{morphisme}, si il vérifie:
\[ 
   \forall x, y \in E \; ; \; \varphi(x \star y) = \varphi(x) \cdot \varphi(y)
\]
\begin{center}
   \textit{Les morphismes préservent dans une certaine mesure la structure opératoire.}
\end{center}
En termes de vocabulaire, on définit alors: 
\begin{itemize}
   \item \textbf{Les endormorphismes} commme les morphismes de \(M\) dans lui-meme.
   \item \textbf{Les isomorphismes} commme les morphismes bijectifs.
   \item \textbf{Les automorphismes} commme les morphismes bijectifs de \(M\) dans lui-meme.
\end{itemize}
La recherche d'isomorphismes est un thême principal en algèbre des structures, en effet, trouver un isomorphisme entre une structure simple et une structure complexe permet de mieux comprendre cette dernière par l'intermédiaire du morphisme.
\subsection*{\subsecstyle{Propriétés des morphismes {:}}}
Pour une structure donnée, on peut montrer que la composée de morphismes et l'inverse d'un morphisme bijectif est un morphisme. En outre on peut caractériser la structure des images directes et réciproques par un morphisme:
\begin{center}
   \textbf{L'image et la préimage d'une sous-structure par un morphisme est une sous-structure.}
\end{center}
Par ailleurs si \( F = \langle f_1, \ldots, f_n \rangle \) est un sous groupe de \( E \) et que \( \phi \) est un morphisme, on a que:
\[ 
   \phi(H) = \langle \phi(h_1), \ldots, \phi(h_n) \rangle
\]
En d'autres termes, \textbf{l'image des générateurs engendre l'image}.
\subsection*{\subsecstyle{Structures Quotients {:}}}
On considère maintenant un ensemble quotient \( E/_\sim \) tel que \( E \) soit muni d'une structure, on cherche alors une condition sur la relation d'équivalence pour que \textbf{la structure soit conservée au passage au quotient}. On peut alors montrer que c'est le cas si et seulement si \(\sim\) est \textbf{compatible} avec les lois, ie que pour toute loi \(\star\), on ait:
\[ 
   x_1 \sim x_2 \text{ et } y_1 \sim y_2 \implies x_1 \star y_1 \sim x_2 \star y_2  
\]
Alors la \textbf{surjection canonique} est un morphisme \(\pi : E \rightarrow E /\sim\) qui a chaque élément associe sa classe d'équivalence pour la relation. 
\chapter*{\chapterstyle{II --- Groupes}}
\addcontentsline{toc}{section}{Groupes}

Soit \(G\) un ensemble \textbf{non-vide} muni d'une loi de composition interne associative\footnote[1]{Dans la suite, la loi de composition des groupes sera notée multiplicativement sauf exceptions.} telle que:
\begin{itemize}
   \item Il existe \textbf{un élément neutre} pour la loi.
   \item Tout élément de \(G\) admet \textbf{un inverse} pour la loi.
\end{itemize}
Alors le couple \((G, \star)\) est appellé \textbf{groupe}. De plus si le groupe est \textbf{commutatif}, on dira alors que c'est un groupe \textbf{abélien}.\<

On appellera \textbf{ordre du groupe} le cardinal (potentiellement infini) de l'ensemble sous-jacent, noté \(|G|\).
\subsection*{\subsecstyle{Exemples {:}}}
On peut alors considérer plusieurs groupes remarquables:
\begin{itemize}
   \item Les \textbf{entiers relatifs} muni de l'addition usuelle.
   \item Les \textbf{isométries du plan} muni de la composition, on l'apelle le \textbf{groupe dihédral}.  
   \item Les \textbf{matrices inversibles} muni de la multiplication, on l'apelle le \textbf{groupe linéaire}.
   \item Les \textbf{bijections} sur un ensemble muni de la composition, on l'apelle le \textbf{groupe symétrique}.
\end{itemize}
\subsection*{\subsecstyle{Morphismes de groupes {:}}}
Soit \(G, H\) deux groupes et \(\varphi: G \rightarrow H\), l'existence d'un élément neutre nous permet de définir alors \textbf{le noyau d'un morphisme} par:
\[
   \text{Ker}(\varphi) := \Bigl\{ x \in G \; ; \; \varphi(x) = e_H \Bigl\}
\]
On montre facilement que c'est un sous-groupe (normal) et on peut alors montrer qu'un morphisme est \textbf{injectif si et seulement si son noyau est réduit à l'élément neutre.} 
\subsection*{\subsecstyle{Sous-groupes {:}}}
Les sous-structures dans le cas des groupes sont naturellement les sous-groupes. On peut alors caractérisé \textbf{le sous-groupe engendré} par \(H\) (défini au premier chapitre) par:
\[ 
   \langle H \rangle := \Bigl\{ h_1^{k_1}h_2^{k_2} \ldots h_n^{k_n}\; ; \; n \in \N \; , \; h_i \in H \; , \; k_i \in \Z \Bigl\}
\]
On peut alors considérer le sous-groupe engendré par un élément \(h \in H\), en effet on a:
\[
   \langle h \rangle := \left\{ h^{k} \; ; \; k \in \Z \right\}
\]
On peut alors définir \textbf{l'ordre d'un élément} comme étant l'ordre du sous-groupe engendré associé (potentiellement infini).\<

Ce sous-groupe permet de définir des groupes remarquables, en effet si un groupe est engendré par un unique élément, il est appelé \textbf{groupe cyclique} dont nous parleront plus loin dans ce chapitre.
\pagebreak
\subsection*{\subsecstyle{Classes {:}}}
On considère maintenant un sous-groupe \( H \leq G \), alors on peut définir deux relations d'équivalences sur \( G \) par:
\[ 
   \begin{cases}
      g_1 \sim g_2 \iff \exists h \in H \; ; \; g_1 = g_2h\\
      g_1 \sim g_2 \iff \exists h \in H \; ; \; g_1 = hg_2
   \end{cases}
\] 
On appelle alors \textbf{classe à gauche} (resp. classe à droite) les classes d'équivalences pour ces deux relations et on note alors \( gH \) (resp. \( Hg \)) la classe d'un élément \( g \) pour cette relation. On note alors \( G/H \) l'ensemble quotient associé aux classes à gauche.
\subsection*{\subsecstyle{Théorème de Lagrange {:}}}
Ces classes induisent donc une partition de \( G \) en classes \textbf{de même cardinal}, en effet:
\[ 
   |gH| = \left|\left\{ gh \; ; \; h \in H \right\} \right| = |H|
\]
En outre on a une bijection qui associe à chaque élément de \( g \) sa classe et l'élément de \( H \) lui correspondant:
\[ 
   \begin{aligned}
      f : G &\longrightarrow (G/H, H)\\
      g &\longmapsto (aH, h)
   \end{aligned}
\]
Ceci nous permet donc de montrer le \textbf{théorème de Lagrange} qui nous donne que pour tout groupe fini \( G \), on a:
\[ 
   |G| = |G/H||H|
\]
Et comme corollaire immédiat la propriété suivante:
\begin{center}
   \textbf{Le cardinal d'un sous-groupe divise le cardinal du groupe.}
\end{center}
\subsection*{\subsecstyle{Sous-groupes normaux {:}}}
On cherche alors à caractériser les sous-groupes tels que la relation d'équivalence définie ci-dessous soit \textbf{compatible} avec les opération de groupe, en d'autres termes on cherche à définir un groupe quotient pour cette relation. On peut alors montrer que les sous-groupes vérifiant cette compatibilité vérifient:
\[ 
   \forall g \in G \; ; \; gH = Hg 
\]
En d'autres termes les classes à droite et à gauche coincident. C'est alors immédiat que \textbf{tout sous-groupe d'un groupe abélien est normal}. Par ailleurs on peut caractériser les sous-groupes normaux d'une autre façon (détaillée au chapitre sur les actions de groupe) comme les sous-groupes qui vérifient:
\[ 
   \forall h \in H \; , \; \forall g \in G \; ; \; ghg^{-1} \in H 
\]
La propriété fondamentale de ces groupes, qui utilise le premier résultat du chapitre suivant est que les sous groupes normaux de \( G \) sont exactement les \textbf{noyaux} de morphismes de domaine \( G \).
\chapter*{\chapterstyle{II --- Théorèmes d'isomorphismes}}
\addcontentsline{toc}{section}{Théorèmes d'isomorphismes}
Une des motivations de la notion de groupe quotient est entre autres de pouvoir trouver des \textbf{isomorphismes} entre des groupes connus, dans ce chapitre, on énonce les trois grands théorèmes utilisables pour atteindre cet objectif.

\subsection*{\subsecstyle{Premier théorème d'isomorphisme {:}}}
Soit \(\phi : G \longrightarrow F\) un morphisme, on rapelle que tout les noyaux sont normaux et on peut alors montrer qu'il existe un unique isomorphisme \(\widetilde{\phi} : G/\Ker{\phi} \longrightarrow F\) tel que le diagramme soit commutatif \footnote[1]{Un \textbf{diagramme commutatif} est une collection d'objets et de morphismes tels tout les chemins (de composition) partant d'un objet vers un autre donnent le meme résultat (ie sont le meme morphisme).}:
\begin{center}
   \begin{tikzpicture}[baseline= (a).base]
      \node[scale=1.25] (a) at (0,0){
         \begin{tikzcd}[row sep = large, column sep = large]
            G \arrow[d, "\pi", swap, two heads] \arrow[r, "\phi"] & F\\
            G/\Ker{\phi} \arrow[r, "\widetilde{\phi}", dashed] & \text{Im}(f) \arrow[u, "\iota", swap, hook]
         \end{tikzcd}
      };
   \end{tikzpicture}
\end{center}
En effet, le passage au quotient rend le morphisme injectif, donc surjectif sur son image, et le diagramme commute, ie on a \( \phi = \iota \circ \widetilde{ \phi} \circ \pi \).\<

De manière plus générale, on a la \textbf{propriété universelle du quotient} pour \( H \unlhd G \) tel que \( H \subseteq \ker(\phi) \), alors on a l'existence d'un morphisme \( \widetilde{\phi} \) tel que le diagramme suivant commute:
\begin{center}
   \begin{tikzpicture}[baseline= (a).base]
      \node[scale=1.25] (a) at (0,0){
         \begin{tikzcd}[row sep = large, column sep = large]
            G \arrow[d, "\pi", swap, two heads] \arrow[r, "\phi"] & F\\
            G/\Ker{\phi} \arrow[ur, "\widetilde{\phi}", swap, dashed]
         \end{tikzcd}
      };
   \end{tikzpicture}
\end{center}
\subsection*{\subsecstyle{Deuxième théorème d'isomorphisme {:}}}
On considère ici deux sous groupe normaux \( H, K \) de \( G \) tel que \( H \subseteq K \), alors on a les deux projections suivantes:
\begin{center}
   \begin{tikzpicture}[baseline= (a).base]
      \node[scale=1.25] (a) at (0,0){
         \begin{tikzcd}[row sep = large, column sep = large]
            G \arrow[d, "\pi_1", swap, two heads] \arrow[r, "\pi_2", two heads] & G/K\\
            G/H
         \end{tikzcd}
      };
   \end{tikzpicture}
\end{center}
On peut alors utiliser la propriété universelle du quotient pour compléter le diagramme par un morphisme \( \phi \) (par ailleurs surjectif):
\begin{center}
   \begin{tikzpicture}[baseline= (a).base]
      \node[scale=1.25] (a) at (0,0){
         \begin{tikzcd}[row sep = large, column sep = large]
            G \arrow[d, "\pi_1", swap, two heads] \arrow[r, "\pi_2", two heads] & G/K\\
            G/H \arrow[ru, "\phi", dashed, two heads]
         \end{tikzcd}
      };
   \end{tikzpicture}
\end{center}
Enfin, on peut appliquer le premier théorème d'isomorphisme à \( \phi \) pour obtenir le diagramme suivant:
\begin{center}
   \begin{tikzpicture}[baseline= (a).base]
      \node[scale=1.25] (a) at (0,0){
         \begin{tikzcd}[row sep = large, column sep = large]
            G \arrow[d, swap, "\pi_1", two heads] \arrow[r, "\pi_2" two heads]&  G/K\\
            G/H \arrow[ru, "\phi", two heads, dashed] \arrow[d, "\pi", swap, two heads]&    \\
            (G/H)/Ker(\phi) \arrow[ruu, "\widetilde{\phi}",bend right, dashed]&   
         \end{tikzcd}
      };
   \end{tikzpicture}
\end{center}
On peut alors montrer que \( \text{Ker}(\phi) = K/H\) et donc qu'on a l'isomorphisme suivant:
\[ 
   (G/H)/(K/H) \cong G/K
\]
\subsection*{\subsecstyle{Troisième théorème d'isomorphisme {:}}}

\subsection*{\subsecstyle{Caractère universel {:}}}
Le parti pris a été fait de mettre cette section dans le chapitre sur les groupes, mais ceci est trompeur, les trois théorèmes ci-dessus sont en fait vrais dans un cadre bien plus général, et pour des objets bien plus généraux apellés \textbf{algèbres universelles}, en particulier tout structure sur laquelle on peut définir une notion de quotient compatibles avec les opérations vérifie alors des analogues de ces théorèmes. En particulier:
\begin{itemize}
   \item On peut quotienter un ensemble par la relation d'équivalence "avoir la même image" et obtenir alors de tels théorèmes.
   \item On peut quotienter un anneau par un \textbf{idéal} et obtenir alors de tels théorèmes.
   \item On peut quotienter un espace vectoriel (ou même un module) par un sous-espace et obtenir alors de tels théorèmes.
\end{itemize}
\subsection*{\subsecstyle{Applications {:}}}
\chapter*{\chapterstyle{II --- Actions de groupe}}
\addcontentsline{toc}{section}{Actions de groupe}
Soit \( G \) un groupe et \( X \) un ensemble quelconque, dans ce chapitre on définit un notion fondamentale en théorie des groupes, la notion \textbf{d'action d'un groupe sur un ensemble.} En effet on appelera \textbf{action} du groupe \( G \) sur \( X \) une application de la forme:
\[ 
   \begin{aligned}
      G \times X &\longrightarrow X\\
      (g, x) &\longmapsto g \cdot x
   \end{aligned}
\]
En outre une action doit vérifier deux autres propriétés:
\begin{itemize}
   \item \textbf{Le neutre n'agit pas: } \( \forall x \in X \; ; \; e \cdot x = x \)
   \item \textbf{Associativité mixte: } \( \forall g_1, g_2, x \in G \times G \times X \; ; \; (g_1g_2) \cdot x = g_1(g_2 \cdot x) \)
\end{itemize}
On dira alors que \( G \) \textbf{agît} sur \( X \) et on notera alors \( G \curvearrowright X \).

\subsection*{\subsecstyle{Morphisme structurel{:}}}
On se donne une action \( G \curvearrowright X\), alors il peut être utile de considérer la currifiée\footnote[1]{On rapelle que \( \mathcal{F}(E \times F, G) \cong \mathcal{F}(E, \mathcal{F}(F, G)) \) en tant qu'ensembles.} de cette action, ie:
\[ 
   \begin{aligned}
      \phi : G &&\longrightarrow (X &\longrightarrow X)\\
      g &&\longmapsto (x &\longmapsto g \cdot x)
   \end{aligned}
\]
On peut alors montrer que cette fonction prends son image dans l'ensemble des bijections sur \( X \) (dont on montrera que c'est un groupe au chapitre sur le groupe symétrique) et que c'est un \textbf{morphisme de groupe}. L'action de \( G \) induit donc un morphisme de groupe, appelé \textbf{morphisme structurel} de la forme:
\[ 
   \phi : G \longmapsto \mathfrak{S}(X)
\]
En outre cette correspondante est bijective, il est donc équivalent de considérer une action d'un groupe sur un ensemble ou un morphisme structurel.
\subsection*{\subsecstyle{Action induite sur l'ensemble des parties {:}}}
Si \(G\) agît sur \( X \) alors \( G\) agît alors naturellement sur \( \mathcal{P}(X)  \) par l'action:
\[ 
   (g, P) \mapsto g \cdot P := \left\{ g \cdot x \; ; \; x \in P \right\} 
\]
\subsection*{\subsecstyle{Action induite sur les sous structures{:}}}
On se pose alors deux questions naturelles:
\begin{itemize}
   \item Une action de \( G \) sur \( X \) induit-elle nécessairement une action de \( G \) sur \( Y \subseteq X \) ?
   \item Une action de \( G \) sur \( X \) induit-elle nécessairement une action de \( H \leq G \) sur \(X\) ?
\end{itemize}
On peut alors montrer que la première question admet une réponse positive si et seulement si \( Y \) est \textbf{stable par l'action}.\<

Pour la seconde question, elle admet toujours une réponse positive et on a même le résultat général suivant gràce au morphisme structurel, on considère deux groupes \( G, H \) reliés par un morphisme \( \phi \), et une action de \( H \) sur \( X \) de morphisme structurel \( \psi \), alors on a le diagramme:
\begin{center}
   \begin{tikzcd}[column sep=large, row sep=large]
      G \arrow[r, "\phi"]
         & H \arrow[r, "\psi"] & X
   \end{tikzcd}
\end{center}
Et donc \( \phi \circ \psi \) définit bien un morphisme structurel de \( G \) sur \( \mathfrak{S}(X) \) et donc une action. Le cas particulier des sous-groupes se déduit en considérant \( \phi \) le morphisme d'inclusion d'un sous-groupe dans le groupe total.
\pagebreak
\subsection*{\subsecstyle{Orbites {:}}}
Considérons un point \( a \in X \), alors on définit \textbf{l'orbite} de \( a \) sous l'action du groupe \( G \) par:
\[ 
   \text{Orb}_G(a) := \left\{ g \cdot a \; ; \; g \in G \right\} 
\]
Intuitivement, ce sont tout les points atteints par l'action de \( G \) sur le point initial \( a \). Une propriété fondamentale des orbites est la suivante, si on considère la relation suivante:
\[ 
   x \sim y \iff y \in \text{Orb}_G(x)
\]
Alors c'est une \textbf{relation d'équivalence}, et on a donc toujours une \textbf{partition} de \( X \) associée à l'action de \( G \), c'est la partition en orbites.
\subsection*{\subsecstyle{Stabilisateurs {:}}}
Considérons un point \( a \in X \), alors on définit \textbf{le stabilisateur} de \( a \) sous l'action du groupe \( G \) par:
\[ 
   \text{Stab}_G(a) := \left\{ g \in G \; ; \; g(a) = a\right\} 
\]
Intuitivement, ce sont tout les éléments du groupe qui laissent \( a \) invariant. Une propriété fondamentale des stabilisateurs est que c'est un \textbf{sous-groupe} du groupe \( G \). En outre si on considère le morphisme structurel \( \phi \) de l'action, on a:
\[ 
   \text{Ker}( \phi) = \bigcap_{x \in X} \text{Stab}_G(x) 
\]
\subsection*{\subsecstyle{Généralisations aux parties {:}}}
On peut alors noter qu'il est aussi possible de définir les orbites et stabilisateurs de \textbf{parties}, en considérant les orbites et stabilisateurs pour l'action induite sur les parties définie plus haut.
\subsection*{\subsecstyle{Vocabulaire {:}}}
On peut alors nommer les actions de groupes qui vérifient certaines propriétés relatives aux ensembles définis plus haut, on appelle alors:
\begin{itemize}
   \item Action \textbf{transitive} une action qui n'admet qu'une seule orbite.
   \item Action \textbf{libre} une action dont tout les stablisateurs sont triviaux.
   \item Action \textbf{fidèle} une action dont le noyau du morphisme structurel est trivial\footnote[1]{On a alors d'aprés la caractérisation du noyau ci-dessus que toute action \textbf{libre} est \textbf{fidèle}.}.
\end{itemize}
On dira aussi qu'une action transitive et libre est \textbf{simplement transitive}, et on peut caractériser cette action par le fait que pour tout paire d'éléments \( x, y \in E\), il existe un \textbf{unique} élement de \( g \) qui relie \( x \) à \( y \).
\subsection*{\subsecstyle{Action par automorphismes intérieurs{:}}}
On peut alors aussi étudier l'action du groupe \( G \) sur \textbf{lui-même}, on obtient alors un nouveau moyen d'étude du groupe \( G \), en particulier, on a deux actions remarquables:
\begin{itemize}
   \item \textbf{L'action par translation:} \( \forall g, h \in G, g \cdot h = gh\)
   \item \textbf{L'action par conugaison:} \( \forall g, h \in G, g \cdot h = ghg^{-1}\)
\end{itemize}
Ceci permet une reformulation plus élégante du concept de sous-groupe normal, en effet un sous-groupe est normal si et seulement si il est \textbf{stable par l'action de conjugaison}.
\pagebreak 
\subsection*{\subsecstyle{Centralisateur{:}}}
Le stabilisateur d'un élément \( g \) pour la relation de conjugaison est alors appelé \textbf{centralisateur} et noté \( Z(g) \), et c'est l'ensemble des éléments qui commutent avec \( g \).\<

On peut définir le centralisateur d'une partie, noté \( Z(H) \) qui est l'intersection de tout les centralisateurs de ses éléments, ie l'ensemble des éléments du groupe qui commutent avec tout les éléments de \( H \), ie on a:
\[ 
   Z(H) := \left\{ g \in G \; ; \; \forall h \in P \; , \; gh = hg\right\}  
\]
En particulier pour tout groupe \( G \), on appelle \textbf{centre} du groupe et on note \( Z(G) \), l'ensemble des éléments qui commutent avec tout les autres éléments. 
\subsection*{\subsecstyle{Normalisateur{:}}}
En affaiblissant la définition ci dessus, on peut définir le \textbf{normalisateur} d'une partie \( H \), noté \( N(H) \), et c'est le stabilisateur de l'action par la conjugaison sur les \textbf{parties}, ie:
\[ 
   N(H) := \left\{ g \in G \; ; \; gH = Hg\right\}  
\]
\subsection*{\subsecstyle{Relation orbites stabilisateurs{:}}}
On peut alors montrer que si on fixe \( x \in X \), alors il existe une bijection entre \( G/\text{Stab}(x) \longrightarrow \text{Orb}(x)\) et en particulier, on a alors la relation fondamentale suivante dite \textbf{relation orbites-stabilisateurs}:
\[ 
   \left|G \right| = \left|\text{Orb}(x)\right| \left|\text{Stab}(x)\right|
\]
Et donc en particulier, le cardinal d'une orbite (ou d'un stabilisateur) \textbf{divise l'ordre de } \( G \).
\subsection*{\subsecstyle{Formules des classes{:}}}
On peut alors utiliser le fait que \( X \) se partitionne en orbites pour obtenir une expression du cardinal de \( X \) apellée \textbf{formule des classes} où \( n \) désigne le nombre d'orbites:
\[ 
   \left|X\right| = \sum_{i = 1}^n  \left| \text{Orb}(x_i) \right| = \sum_{i = 1}^n  \frac{\left|G \right|}{\left|\text{Stab}(x_i)\right|}
\]
Un des intérêts de cette formule est par exemple qu'elle permet de connaître le nombre d'orbites d'une action ou de montrer l'existence de points fixes (ie de points dont l'orbite est de cardinal 1), en effet on considère les diviseurs de l'ordre du groupe \( (d_1, \ldots, d_k) \) et \( (a_1, \ldots, a_k) \) le nombre d'orbites de cette taille, on obtient alors une equation de la forme suivante, qui peut souvent s'étudier facilement dans les cas simples avec peu de diviseurs:
\[ 
   |X| = \sum a_kd_k 
\]
\subsection*{\subsecstyle{Formules de Burnside{:}}}
Une autre formule important liée aux actions de groupe est \textbf{la formule de Burnside} qui permet de dénombrer les orbites de l'action, et en particulier, on peut alors \textbf{compter des éléments modulo une action de groupe}, on a la formule suivante:
\[ 
   n = \frac{1}{|G|} \sum_{g \in G} |\text{Fix(g)}| 
\]
Où \( \text{Fix(g)} := \left\{x \in X \; ; \; g \cdot x = x \right\}\) est l'ensemble des points fixés par \( g \). Cette formule est fondamentale en combinatoire, par exemple imaginons que nous souhaitions compter le nombre de colliers \textbf{différents} de 5 perles à deux couleurs. Alors ici "différents" signifie que un des colliers dénombré est égal à un autre aprés une rotation ou une reflexion, on considèrera ce collier comme le même que le premier. 
\begin{center}
   \textit{L'idée principale est donc bien de compter des éléments modulo l'action sur l'ensemble, ie en identifiant deux éléments dans la même orbite.}
\end{center}
Compter ces colliers revient donc à compter les orbites de l'action par symétries d'un groupe sur l'ensemble de tout les colliers possibles. Et la formule de Burnside nous permet donc d'effectuer ce calcul.
\chapter*{\chapterstyle{II --- Groupes Symétriques}}
\addcontentsline{toc}{section}{Groupe Symétrique}
On appelle \textbf{groupe symétrique} et on note \(\mathfrak{S}_n\) le groupe des \textbf{permutations} de l'ensemble \(\inticc{1}{n}\) muni de la composition des applications.\<

Soit \(\sigma \in \mathfrak{S}_n\) une permutation de \(\inticc{1}{n}\), alors c'est une fonction bijective sur cet ensemble. En particulier, sachant que l'ensemble est fini, c'est une fonction définie par cas qu'on note alors par commodité horizontalement dans un tableau:
\[
   \sigma =  \begin{pmatrix}
      1 & 2 & \ldots & n\\
      \sigma(1) & \sigma(2) & \ldots & \sigma(n)
   \end{pmatrix}
\]
On remarque que ce groupe est doté d'une action naturelle sur \( \inticc{1}{n} \) donnée par \( \sigma \cdot k = \sigma(k) \).
\subsection*{\subsecstyle{Support {:}}}
On appelle alors \textbf{support} d'une permutation le complémentaire des points fixes de \(\sigma\), ie on a:
\[
   \text{Supp}(\sigma) := \bigl\{ i \in \N \; ; \; \sigma(i) \neq i \bigl\}   
\]
Une des propriétés qu'on peut déduire directement de cette définition est que deux permutations à supports disjoints commutent.
\subsection*{\subsecstyle{Cycles {:}}}
On appelle \textbf{k-cycle}\footnote[1]{Si \( k = 2 \), on appellera un tel \( k \)-cycle une \textbf{transposition}.} une permutation \(\sigma\) telle qu'il existe \(k \geq 2\) et \(k\) éléments deux à deux distincts \(a_1, \ldots, a_k\) tels que:
\[
   \begin{cases}
      \forall i \in \inticc{1}{k-1} \; ; \; \sigma(a_i) = \sigma(a_{i+1}) \\
      \forall i \notin \inticc{1}{k} \; ; \; \sigma(a_i) = \sigma(a_{i}) \\
      \sigma(a_k) = \sigma(a_1)
   \end{cases} 
\]
On peut alors noter un tel cycle par la notation suivante qui décrit tout les éléments affectés par la permutation:
\[
   \sigma = (a_1, \ldots, a_n)  
\]
\underline{Exemple:} La permutation suivante est un 3-cycle:
\[
   \sigma =  \begin{pmatrix}
      1 & 2 & 3 & 4\\
      2 & 3 & 1 & 4
   \end{pmatrix} = (1 \;\, 2 \;\, 3)
\]
\subsection*{\subsecstyle{Cycles et orbites {:}}}
Si \(\sigma\) est un \(k\)-cycle et que \(a\) n'est pas un point fixe, alors on en déduit que la donnée du support de \(\sigma\) est équivalente à la donnée de l'orbite de celle-ci (plus précisément du sous groupe engendré par celle-ci) pour son action naturelle, ie:
\[
   \text{Supp}(\sigma) = \bigl\{a, \sigma(a), \sigma^2(a), \ldots, \sigma^{k-1}(a) \bigl\} = \text{Orb}_\sigma(a)
\]
\subsection*{\subsecstyle{Ordre {:}}}
On peut alors démontrer une propriété fondamentale de l'ordre des cycles:
\begin{center}
   \textbf{Un \(k\)-cycle est d'ordre \(k\)}.
\end{center}

En effet si on considère le sous-groupe engendré par un tel cycle, on remarque que pour tout élément \(a \in \inticc{1}{n}\) \(\sigma^{k}(a) = a\), donc \(\sigma^{k} = \text{Id}\).
\subsection*{\subsecstyle{Théorème de décomposition en cycles {:}}}
Une des problématiques principales à propos des groupes symétriques est la question de la décomposition d'une permutation en permutation plus simples. On peut tout d'abord montrer que \textbf{toute permutation se décompose en produit de cycles à support disjoints}.\<

Pour ceci, on utilise le fait que toute permutation induit une \textbf{partition en orbites} de \( \inticc{1}{n} \), ces orbites correspondront alors au supports des cycles dans la décomposition. Il reste à choisir un représentant de chaque orbite et la décomposition en cycles est acquise.
\subsection*{\subsecstyle{Théorème de décomposition en transpositions {:}}}
Par la suite, on peut alors constater directement que pour tout \(k\)-cycle \(\sigma = (a_1 \;\, \ldots \;\, a_k)\), on a une décomposition canonique en produit de transpositions:
\[ 
   \sigma = (a_1 \;\, a_2)(a_2 \;\, a_3)\ldots(a_{k-1} \;\, a_k)
\]

Enfin, on conclura de ces deux propositions que \textbf{toute permutation se décompose en produit de transpositions}, ou en d'autres termes si on note \(\mathfrak{T}_n\) l'ensemble des transpositions:
\[ 
   \langle \mathfrak{T}_n \rangle = \mathfrak{S}_n
\]
\subsection*{\subsecstyle{Conjugaison et permuations {:}}}
On considère alors l'action de \(  \mathfrak{S}_n \) sur lui-même par conjugaison, on peut alors montrer que pour toute permutation \(\sigma\), on a:
\[ 
   \sigma(a_1, \ldots, a_n)\sigma^{-1} = (\sigma(a_1), \ldots, \sigma(a_n))
\]
En particulier, on a alors que deux cycles sont conjugués si et seulement si ils ont la même longueur, et si on définit le \textbf{type d'une permutation} par le n-uplet \textbf{non ordonné} \( [l_1, \ldots, l_k] \) des longueurs des cycles dans sa décomposition en cycles, on a alors une caractérisation des classes de conjugaisons:
\begin{center}
   \textbf{Deux permutations sont conjuguées si et seulement si elles ont même type.}
\end{center}
\subsection*{\subsecstyle{Signature {:}}}
On considère une permutation \( \sigma \) de type \( [l_1, \ldots, l_k] \), alors chacun de ses cycles se décompose en \textbf{le} produit de \( l_i-1 \) transpositions défini ci-dessus. Il est alors naturel de définir alors la fonction suivante:
\[ 
   m(\sigma) = \sum_{i \leq k} (l_i-1)
\]
C'est le total du nombre de transpositions dans la décomposition en transpositions définie plus haut. On peut alors définir la \textbf{signature} d'une permutation par:
\[ 
   \epsilon(\sigma) = (-1)^{m(\sigma)} 
\]
On montre alors facilement que cette fonction est un \textbf{morphisme de groupe} de \( \mathfrak{S}_n \longrightarrow ( \left\{ -1 , 1 \right\}, \times ) \) et que trivialement la signature d'une transposition est \( -1 \).
\begin{itemize}
   \item Si \( \epsilon( \sigma) = 1\), on dira que cette permutation est \textbf{paire}.
   \item Si \( \epsilon( \sigma) = -1\), on dira que cette permutation est \textbf{impaire}.
\end{itemize}
L'ensemble des permutations de signature paire est alors un groupe (c'est le noyau de \( \epsilon \)), qu'on appelle \textbf{groupe alterné} et qu'on note \( \mathfrak{A}_n \).
\chapter*{\chapterstyle{II --- Groupes Cycliques}}
\addcontentsline{toc}{section}{Groupes Cycliques}
On appelle \textbf{groupe cyclique} un groupe \(G\) engendré par un unique élément qu'on notera \(g\). Le but de ce chapitre est de classifier ces groupes et d'identifier leurs caractéristiques.\<
 
On considère tout d'abord le groupe quotient \( \Z /n\Z \), on peut alors remarque que les éléments de ce groupe sont exactement \textbf{les classes de restes possibles par la division euclidienne par \( n \)}. On notera l'égalité dans ce contexte \( a = b \text{ (mod } n) \) en comprenant que ceci signife que \( a + n\Z = b + n\Z \)

\subsection*{\subsecstyle{Classification {:}}}
Dans cette section on retourne dans le case d'un groupe cyclique général \( G \) et on définit le morphisme surjectif suivant:
\[
   \begin{aligned}
      \phi: \Z &\longrightarrow G\\
      n &\longmapsto g^n
   \end{aligned}
\]
On raisonne sur la finitude de \( G \) et on peut alors caractériser tout les groupes cycliques trés simplement, en effet:
\begin{itemize}
   \item Si \(G\) est infini, le morphisme \(\phi\) est \textbf{injectif} et on a l'isomorphisme \( G \cong \Z \)
   \item Si \(G\) est fini, on utilise le \textbf{premier théorème d'isomorphisme} et on a l'isomorphisme  \( G \cong \Z/n\Z \)
\end{itemize}
\begin{center}
   \textit{Il n'y a donc qu'un seul groupe cyclique d'ordre n (resp. d'ordre infini), celui des classes de congruences modulo n (resp. celui des entiers).}
\end{center}
On remarque alors l'importance du groupe quotient \( \Z/n\Z \), c'est le prototype de groupe cyclique fini.
\subsection*{\subsecstyle{Générateurs de \( \Z/n\Z \) {:}}}
On sait donc que ce groupe est \textbf{cyclique} d'ordre \( n \), en particulier il est engendré par \( 1 \), mais aussi par toutes les classes dont le représentant est premier avec \( n \), en effet si \( a \) est un tel élément alors d'aprés le théorème de Bézout, on a:
\[ 
   \exists u, v \in \Z \; ; \; au + bn = 1 
\]
Donc en particulier \( a + \ldots + a = 1 \mod{n}\) et par la suite, \( a \) engendre tout le groupe. Il y a donc \( \varphi(n) \) générateurs de ce groupe.
\subsection*{\subsecstyle{Théorème chinois {:}}}
Un des grands théorèmes sur les groupes cycliques est le suivant, si on considère \( p_1, \ldots, p_k \in \N \) des nombres premiers entre eux, et qu'on note \( n \) leur produit, alors on peut montrer facilement qu'on a l'isomorphisme suivant:
\[ 
   \Z/n \Z \cong \Z/ p_1 \Z \times \ldots \times \Z/ p_k \Z
\]
En particulier si \( n = p_1^{\alpha_1} \ldots p_k^{\alpha_k} \) décompé en facteurs premiers, alors on a:
\[ 
   \Z/n \Z \cong \Z/ p_1^{ \alpha_1} \Z \times \ldots \times \Z/ p_k^{ \alpha_k} \Z
\]
C'est la \textbf{décomposition primaire d'un groupe cyclique}. Elle s'interprète en comprenant par exemple que la donnée du reste par 6 d'un entier est exactement equivalente à la donnée de son reste par 3 et 2.

\chapter*{\chapterstyle{II --- Anneaux}}
\addcontentsline{toc}{section}{Anneaux}
Soit \(A\) un ensemble \textbf{non-vide} muni de deux lois de composition internes associatives notées \(+, \times\) telles que:
\begin{align*}
   &\bullet \;\; (A, +) \text{ soit un groupe commutatif.} \\
   &\bullet \;\; \text{La loi \(\times\) est associative.}\\
   &\bullet \;\; \text{La loi \(\times\) est distributive sur la loi \(+\).}\\
   &\bullet \;\; \text{Il existe \textbf{un élément neutre} pour la loi \(\times\).}
\end{align*}
Alors le triplet \((A, +, \times)\) est appellé \textbf{anneau}. Si la loi multiplicative est \textbf{commutative}, on dira alors que c'est un anneau commutatif. On définit aussi de nouveau types d'élément remarquable spécifiques au cas des anneaux:
\begin{itemize}
   \item On dit qu'un élément \(x \in A\) est \textbf{un diviseur de zéro}\footnote[1]{Ici c'est un diviseur de zéro \textbf{à droite}, on définit de même les diviseurs de zéro \textbf{à gauche}.} si il existe \( y \) tel que \( xy = 0 \).
   \item On dit qu'un élément \(x \in A\) est \textbf{un nilpotent} si il existe \( n \in \N \) tel que \(x^n = 0\).
\end{itemize}
On définit aussi les \textbf{inversibles} à droite ou à gauche pour la seconde loi. On dira qu'un anneau sans diviseurs de zéro est \textbf{intègre}, et dans ce cas on a la propriété suivante trés puissante:
\[ 
   \forall x, y \in A \; ; \; xy = 0 \implies x = 0 \text{ ou } y = 0 
\]
\subsection*{\subsecstyle{Exemples {:}}}
On peut alors considérer plusieurs anneaux remarquables:
\begin{itemize}
   \item Les \textbf{entiers relatifs} muni des opérations usuelles forment un anneau intègre.
   \item Les \textbf{polynomes} muni de la somme et du produit forment un anneau intègre.
   \item Les \textbf{fonctions continues} muni de la somme et du produit forment un anneau.
   \item Les \textbf{matrices} muni de la somme et du produit forment un anneau.
\end{itemize}

\subsection*{\subsecstyle{Propriétés Algébriques{:}}}
Pour deux éléments \(a, b \in A\) qui commutent, on a \textbf{la formule du binome de Newton}:
\[
   (a + b)^n = \sum_{k=0}^{n}\binom{n}{k} a^k b^{n-k}   
\]
\subsection*{\subsecstyle{Sous-anneaux {:}}}
Les sous-structures dans le cas des groupes sont naturellement les \textbf{sous-anneaux}. Un cas remarquable est celui du \textbf{sous-anneau engendré} par \(H\):
\[ 
   \langle H \rangle := \left\{ \sum_{k=1}^{n} \pm h_1^{k_1}h_2^{k_2} \ldots h_n^{k_n}\; ; \; n \in \N \; , \; h_i \in H \; , \; k_i \in \N \right\}
\]
On peut alors imagine généraliser la notion de sous-groupe normal, ie une sous-structure qui permet de quotient, mais il se trouve qu'alors la notion de sous-anneau engendré n'est pas la bonne notion, et on définit plutôt la notion \textbf{d'idéal} qui est un sous groupe additif de \(A\) qui soit stable par multiplication (à droite et à gauche) par n'importe quel élément de l'anneau.

\subsection*{\subsecstyle{Caractéristique {:}}}
On définit la caractéristique d'un anneau non-nul par:
\[
   \text{car}(A) := \min \left\{ n \in \N \; ; \;\underbrace{1 + \ldots + 1}_{\text{\(n\) sommandes}} = 0 \right\}
\]
Une autre formulation serait simplement que:
\begin{center}
   \textit{La caractéristique d'un anneau est l'ordre (additif) de l'unité multiplicative.}
\end{center}
\subsection*{\subsecstyle{Anneaux à PGCD {:}}}
\subsection*{\subsecstyle{Anneaux Factoriels {:}}}
\subsection*{\subsecstyle{Anneaux Principaux {:}}}
\subsection*{\subsecstyle{Anneaux Euclidiens {:}}}
On appelle \textbf{anneau Euclidiens} tout anneau \(A\) principal qui possède une \textbf{division euclidienne}. Dans un tel anneau, on peut alors faire \textbf{de l'arithmétique} comme dans l'anneau des entiers naturels.
\subsection*{\subsecstyle{Schéma heuristique des structures d'anneaux {:}}}
Pour mieux visualiser la hierarchie des différents types d'anneaux, on peut représenter la structure logique sous la forme de la suite d'implications suivantes:
\begin{center}
   \customBox{width = 16cm}{
      \textbf{Euclidien} \(\implies\) \textbf{Principal} \(\implies\) \textbf{Factoriel} \(\implies\) \textbf{PGCD} \(\implies\) \textbf{Intégre} \(\implies\) \textbf{Commutatif}
   }
\end{center}
\chapter*{\chapterstyle{II --- Corps}}
\addcontentsline{toc}{section}{Corps}
Soit \(A\) un anneau dont tout les éléments sauf \(0\) sont inversibles. Alors on dit que \(A\) est \textbf{un corps}.

\subsection*{\subsecstyle{Exemples {:}}}
On peut alors considérer plusieurs corps remarquables:
\begin{itemize}
   \item Les \textbf{réels} muni des opérations usuelles.
   \item Les \textbf{complexes} muni des opérations usuelles.
   \item Les \textbf{quaternions}\footnote[1]{C'est un exemple de corps non commutatif} muni des opérations usuelles.
   \item Les \textbf{corps finis} \(\mathbb{F}_p = \Z/p\Z\) pour \(p\) premier.
   \item Les \textbf{nombres constructibles} à la règle et au compas.
\end{itemize}
\chapter*{\chapterstyle{II --- Corps des Complexes}} % 99% Fini
\addcontentsline{toc}{section}{Corps des Complexes}

On définit le nombre imaginaire \(i\) dont le carré vaut \(-1\), et on construit alors \(\C\) comme l'extension du corps\footnote[1]{La motivation principale de l'introduction de \(i\) et de cette construction est que \(\C\) est algébriquement clos, ie tout les polynomes de degré \(n\) de \(\C[X]\) ont \(n\) racines.} \(\R\) avec les deux lois usuelles, ie on définit:
\[
   \C := \R[i] = \Bigl\{a + ib \; ; \; a, b \in \R \Bigl\}
\]
On peut alors montrer que c'est un ensemble stable pour les lois usuelles et qu'il vérifie toutes les propriétés qui font de lui un \textbf{corps}.\+
Chaque nombre complexe se définit alors comme des sommes ou produits de réels et du nombre imaginaire et on appelle alors cette expression la \textbf{forme algébrique} d'un nombre complexe et on appelle \(a\) \textbf{la partie réelle} et \(b\) \textbf{la partie imaginaire} de ce nombre. \<

Géométriquement, on peut identifier les nombres complexes à des points du plan, en effet, \(a + ib\) peut se comprendre comme une combinaison linéaire d'un nombre de l'axe réel, et d'un nombre de l'axe imaginaire.

\subsection*{\subsecstyle{Module {:}}}
On appelle \textbf{module} de \(z \in \C\) le \textbf{prolongement} de la fonction valeur absolue à \(\C\), c'est donc une \textbf{norme} et on la définit telle que {:}
\[
   |z| = \sqrt{a^2 + b^2} = \sqrt{z\overline{z}} 
\]
Dans la suite, on notera \(\rho\) le module de \(z\) pour faciliter la lecture.

\subsection*{\subsecstyle{Forme trigonométrique {:}}}
L'interprétation géométrique permet alors de montrer par passage en coordonées polaires qu'il existe un unique angle \(\theta\) (modulo \(2\pi\)) qu'on appelle \textbf{argument} de \(z\) tel que:
\[
    z = \rho(\cos\theta+i\sin\theta)   
\]

\subsection*{\subsecstyle{Forme exponentielle {:}}}
De même on définit alors \textbf{la forme exponentielle} de \(z\) l'expression:
\[
    z = \rho e^{i\theta} := \rho(\cos\theta+i\sin\theta)
\]
On peut alors étendre les propriétés usuelles de l'exponentielle à \(\C\) et on en déduit:
\customBox{width=6cm}{
   \begin{align*}
      \arg(zz') = \arg(z) + \arg(z') \mod{2\pi}\\
      \arg(\frac{z}{z'}) = \arg(z) - \arg(z') \mod{2\pi}
   \end{align*}
}

\subsection*{\subsecstyle{Conjugué {:}}}
On appelle conjugaison \textbf{l'involution} qui à \(z\) associe son \textbf{conjugué}, noté \(\overline{z}\) tel que:
\[
    \overline{z} := a - bi = \rho(\cos\theta - i\sin\theta) = \rho e^{-i\theta}
\]
C'est une application \textbf{additive} et \textbf{multiplicative}, on montre alors les formules suivantes {:}
\customBox{width=7.5cm}{
   \[
      \Re(z) := \frac{z + \overline{z}}{2}
      \quad\quad\quad\quad\quad\quad
      \Im(z) := \frac{z - \overline{z}}{2i}
   \]
}

En utilisant ces formules pour \(z\) sous forme exponentielle, on a alors les \textbf{formules d'Euler} qui sont très importantes car elle permettent de \textbf{linéariser} des expression trigonométriques.\<

\subsection*{\subsecstyle{Formule de Moivre {:}}}
Un propriété importante des formes trigonométriques et exponentielles apellée \textbf{formule de Moivre}\footnote[1]{Ici, on a choisi de considérer \(z \in \U\) mais ces propriétés sont vraies pour \textbf{tout nombre complexe}, il suffit alors d'appliquer la puissance au module.} est:
\customBox{width=9cm}{
   \begin{align*}
      (e^{i\theta})^n &= e^{n(i\theta)}\\
      (\cos\theta + i\sin\theta)^n &= \cos n\theta + i\sin n\theta
  \end{align*}  
}
\begin{center}
    \textit{Les différentes puissances d'un nombre complexe (de module 1) s'interprétent alors comme des points situés à equidistance sur un cercle.}
\end{center}
Graphiquement:
\begin{center}
   \begin{tikzpicture}[yscale=2, xscale=2]
      \coordinate (O) at (0,0);
      \coordinate (X) at (1.5,0);
      \coordinate (Z1) at (0.86, 0.5);
      \coordinate (Z2) at (0.5, 0.86);
   
      \draw[-latex] (-1.5,0) -- (X) node [right] {$\mathbb{R}$};
      \draw[-latex] (0, -1.5) -- (0,1.5) node [above] {$i\mathbb{R}$};
   
      \draw[color = DarkBlue1, thick] (0,0) circle (1cm);
   
      \draw node[color = BrightRed1] at (1.25, 0.6) {$z = e^{i\cdot\theta_1}$}; 
      \draw node[color = BrightRed1] at (0.95, 1) {$z^2 = e^{i\cdot 2\theta_1}$}; 
   
      \draw[color = BrightRed1!75, thick] (O) -- (Z1);
      \pic [color = BrightRed1, draw, thick, "$\theta_1$", angle eccentricity=1.5, angle radius=0.5cm] {angle = X--O--Z1};
   
      \draw[color = BrightRed1!75, thick] (O) -- (Z2);
      \pic [color = BrightRed1, draw, thick, "$\theta_1$", angle eccentricity=1.5, angle radius=0.75cm] {angle = Z1--O--Z2};
   
      \fill[color = BrightRed1!100] (0.21, 0.67) circle[radius=0.5pt];
      \fill[color = BrightRed1!80] (0.073, 0.70) circle[radius=0.5pt];
      \fill[color = BrightRed1!60] (-0.07, 0.70) circle[radius=0.5pt];
      \fill[color = BrightRed1!40] (-0.21, 0.67) circle[radius=0.5pt];
      \fill[color = BrightRed1!20] (-0.35, 0.61) circle[radius=0.5pt];
   \end{tikzpicture}  
\end{center}

\subsection*{\subsecstyle{Racines n-ièmes {:}}}
Soit \(n \in \N\), une partie importante des problèmes impliquant des nombres complexes proviennent d'équations d'inconnue \(Z\) de la forme:
\[
   Z^n = z
\]
On peut montrer que l'ensemble des solutions de ce type de problème est:
\customBox{width=8cm}{
   \begin{align*}
      S = \Bigl\{ \sqrt[n]{\rho}e^{i\frac{\theta + 2k\pi}{n}}\; ; \; k \in \bigl\{0, 1, \ldots , n-1 \bigl\} \Bigl\}   
  \end{align*}  
}
\underline{Cas particulier {:}}
Si on a une racine n-ième \(Z_0\) de \(Z\) et qu'on connaît les racines n-ièmes de l'unité, alors on peut obtenir toutes les racines n-ièmes de \(Z\) grâce à:

\[
   \Bigl\{ Z \in \C \; ; \; Z^n = z \Bigl\} = \Bigl\{ Z_0u \; ; \; u \in \U_n \Bigl\}   
\]

\subsection*{\subsecstyle{Le nombre complexe \(j\) {:}}}
On note \(j\) la première racine troisième de l'unité.
Le nombre \(j\) est singulier, car il vérifie:
\customBox{width=4cm}{
   \(
      j^2 = j^{-1} = \overline{j}
   \)
}

Graphiquement, on peut observer que les affixes des nombres \(1\), \(j\) et \(\overline{j}\) forment un triangle équilatéral inscrit dans le cercle trigonométrique.
\chapter*{\chapterstyle{II --- Anneau des Polynômes}} % 99% Fini
\addcontentsline{toc}{section}{Anneau des Polynômes}
Soit \(\mathbb{A}\) un anneau commutatif, on construit l'ensemble des \textbf{polynômes} à coefficients dans \(\mathbb{A}\) comme l'ensemble des suites \textbf{nulles à partir d'un certain rang} d'éléments de \(\mathbb{A}\), on peut alors munir cet ensemble des opérations naturelles suivantes:
\begin{itemize}
   \item Une \textbf{addition} effectuée termes à termes.
   \item Une \textbf{multiplication par un scalaire} effectuée termes à termes.
   \item Une \textbf{multiplication polynomiale} définie par distributivité comme:
   \[ 
      PQ = (p_0q_0, p_1q_0 + p_0q_1, \ldots) = \left( \sum_{k=0}^n P_kQ_{n-k} \right)_{n \in \N} 
   \]
   C'est bien une suite nulle à partir d'un certain rang et elle correspondra alors à la distributivité usuelle\footnote[1]{C'est un cas particulier de produit de convolution discret, voir le chapitre sur la convolution.}.
\end{itemize}
On note alors \( X := (0, 1, 0, \ldots ) \) et on appelle cette suite \textbf{indeterminée}, on remarque alors que:
\[
   \forall n, m \in \N \; ; \; X^nX^m = X^{n + m}
\]
Et par suite que tout polynôme peut s'écrire comme combinaison linéaire de cette indeterminée, ce qui nous donne finalement l'expression canonique d'un polynôme et donc la définition canonique de l'ensemble des polynômes en l'indeterminée \( X \) donnée par:
\[ 
   \mathbb{A}[X] := \left\{ \sum_{n \in \N} a_kX^k \; ; \; (a_k) \in \mathbb{A}^\N \right\} 
\]
Où la suite \( (a_n) \) est nulle à partir d'un certain rang.
\subsection*{\subsecstyle{Structure {:}}}
Ces opérations et la structure d'anneau commutatif des coefficients donnent alors une structure \textbf{d'anneau commutatif} à l'ensemble \( \mathbb{A}[X] \), en outre on pourra aussi vérifier aprés avoir lu le chapitre correspondant que c'est un \textbf{espace vectoriel} de dimension infinie, et dont une base est donnée par:
\[ 
   (1, X, X^2, \ldots) 
\]
Finalement, si \( \mathbb{A} \) est intégre (par exemple dans le cas usuel où c'est un corps), l'anneau \( \mathbb{A}[X] \) l'est aussi.
\subsection*{\subsecstyle{Evaluation {:}}}
Soit \( R \) un anneau quelconque qui contient \( \mathbb{A} \), et \( x \in R \) alors on peut montrer qu'il existe une application fondamentale, dite application \textbf{d'évaluation} donné par:
\[ 
   \begin{aligned}
      \phi : \mathbb{A}[X] \times R &\longrightarrow R \\
      (P, x) &\longmapsto P(x) = \sum a_kx^k
   \end{aligned} 
\]
En effet, si on fixe un élément \( x \in R \), alors on a simplement \( \forall P \in \mathbb{A}[X] \; ; \; \phi(P, x) = P(x) \) qui est simplement le polynôme inital dont on a substitué l'indeterminée par un élément de l'anneau. En particulier si \( R = \mathbb{A}[X] \), on a directement l'identification \( P = P(X) \).
\pagebreak

Dans la suite on se restreint au cas \( \mathbb{A} = \K \) des polynômes à coefficients dans un corps. Cette contrainte supplémentaire nous permettra de développer une arithmétique plus riche des polynômes.
\subsection*{\subsecstyle{Degré et Valuation {:}}}
Soit \(P, Q \in \K[X]\), on peut alors définir tout une propriété fondamentale appelée \textbf{degré} de \(P\) qui découle directement de la construction des polynômes:
\[ 
   \text{deg}(P) := \max\left\{ k \in \N \; ; \; a_k \neq 0 \right\}  
\]
On a alors les propriétés opératoires du degré ci-dessous:
\begin{itemize}
   \item \textbf{Degré de la somme: }\( \deg(P + Q) \leq \max(\deg(P), \deg(Q)) \)
   \item \textbf{Degré du produit: }\( \deg(PQ) = \deg(P) + \deg(Q) \) 
\end{itemize}
La valuation est définie de manière analogue comme le plus petit coefficient non nul de P.
\subsection*{\subsecstyle{Divisibilité {:}}}
On peut naturellement définir une notion de \textbf{divisibilité} dans l'anneau \( \mathbb{A}[X] \) qui vérifie toute les propriétés usuelles, mais la notion de degré nous permet aussi de définir une \textbf{division euclidienne} de deux polynômes qui se comporte comme la division euclidienne usuelle, à la différence que la condition d'arrêt porte sur le \textbf{degré du reste}.\<

Plus précisément, on a le théorème suivant pour tout couple \( A, B \in \K[X] \):
\[ 
   \exists! (Q, R) \in \K[X] \; ; \; A = BQ + R \text{ avec } \text{deg}(R) < \text{deg}(B) 
\]
La démonstration de ce théorème se fait de manière analogue à celui de \( \Z \), ie en exhibant l'algorithme de division. Ce théorème donne alors à \( \K[X] \) une structure \textbf{d'anneau Euclidien}, dont découle les conséquences suivantes:
\begin{itemize}
   \item \textbf{Anneau de Bezout:} La relation de Bezout est vraie pour les polynômes.
   \item \textbf{Anneau principal:} Les idéaux sont principaux.
   \item \textbf{Anneau factoriel:} Il existe une décomposition en facteurs premiers.
\end{itemize}
\subsection*{\subsecstyle{Racines{:}}}
Soit \(\alpha \in \K\) et \( P \in \K[X]\), alors on peut montrer le théorème fondamental ci-dessous:
\[ 
   P(\alpha) = 0 \iff (X - \alpha) | P \iff P \in ((X - \alpha))
\]
On dira alors que \( \alpha \) est \textbf{racine} de \( P \) si une de ces conditions est vérifiée.
\subsection*{\subsecstyle{Multiplicité{:}}}
On appelle \textbf{multiplicité d'une racine} \(\alpha\) l'entier \(m\) tel que:
\[
   \Bigr[ (X - \alpha)^m | P \Bigr] \; \land \; \Bigr[(X - \alpha)^{m+1} \nmid P\Bigr]
\]
On en déduit que pour une racine \(\alpha\) de multiplicité \(m\), on peut \textbf{factoriser} \(P\) par \((X-\alpha)^m\).\<

Si on considère maintenant plusieurs racines \textbf{distinctes} \(a_0, a_1, \ldots, a_{n-1}, a_n\) de multiplicité respectivement \(m_0, m_1, \ldots, m_{n-1}, m_n\), le lemme de Gauss nous permet de montrer qu'alors:
\begin{flalign*}
   \left[ \prod_{i=0}^{n}(X-\alpha_i)^{m_i} \right] \; \biggr| \; P \shorteqnote{(On peut factoriser par le produit des \((X-\alpha_i)^{m_i}\))}
\end{flalign*}
\subsection*{\subsecstyle{Caractérisation de la multiplicité{:}}}
Si on note \(P^{m}\) la dérivée n-ième de \(P\), on peut caractériser le fait que \( \alpha \) soit de multiplicité \( m \) par:
\[
   P^{m}(\alpha) = 0 \; \land \; P^{m + 1}(\alpha) \neq 0
\]
\subsection*{\subsecstyle{Facteurs premiers {:}}}
On appelle \textbf{facteurs premiers} de \( \K[X]\) les polynômes (non-constants) qui n'admettent pas de \textbf{diviseurs stricts} (non-constants), ces éléments dépendents du corps considéré, en effet par exemple:
\begin{itemize}
   \item \textbf{Dans \( \R[X] \):} \(X^2 + 1\) est premier.
   \item \textbf{Dans \( \C[X] \):} \(X^2 + 1 = (X - i)(X + i)\) n'est pas premier.
\end{itemize}
On dira qu'un polynôme est \textbf{scindé} sur \( \K[X] \) si ses facteurs sont tous de degré 1.
\subsection*{\subsecstyle{Décomposition {:}}}
Un des grans thèmes de l'étude des polynômes est alors la recherche de la décomposition de ceux-ci en facteurs premiers, par exemple: 

\begin{itemize}
   \item Si on considère l'anneau \( \C[X] \), on peut alors montrer le \textbf{théorème fondamental de l'Algèbre}:
   \begin{center}
      \textbf{Tout polynôme non-constant admet une racine.}
   \end{center}
   Et donc en particulier par récurrence tout les polynômes de \( \C[X] \) sont \textbf{scindés}.
   \item Si on considère l'anneau \( \R[X] \), il existe donc des polynômes de degré 2 irréductibles. Mais on sait alors qu'il ceux ci ont des racines complexes, et par évaluation on trouve la propriété intéressante suivante:
   \[
      P(z) = 0 \implies P(\overline{z}) = 0
   \]
   \item Si on considère l'anneau \( \mathbb{F}_2[X] \), on peut par exemple remarquer la factorisation:
   \(
      X^2 + 1 = (X + 1)^2 
   \)
\end{itemize}
\subsection*{\subsecstyle{Polynômes en plusieurs indeterminées {:}}}
On peut alors généraliser la construction des polynômes en une indeterminée \( X \) en un anneau de polynômes en plusieurs indeterminées \( \mathbb{A}[X_1, \ldots, X_n] \) qu'on définit par récurrence par:
\[ 
   \mathbb{A}[X_1, \ldots, X_n] =    \left( \mathbb{A}[X_1, \ldots, X_{n-1}] \right)[X_n]
\]
C'est aussi un \textbf{anneau commutatif}, aussi intègre si \( \mathbb{A} \) l'est et ses éléments sont alors de la forme:
\[ 
   \mathbb{A}[X_1, \ldots, X_n] := \left\{ \sum_{i_1, \ldots, i_n \in \N} a_{i_1, \ldots, i_n}X_1^{i_1} \ldots X_n^{i_n}\right\}  
\]
Où la somme est finie, ie où l'ensemble des coefficients \( (a_{i_1, \ldots, i_n})_{i_1, \ldots, i_n \in \N} \) est une famille finie. Quelques exemples:
\begin{itemize}
   \item \textbf{Dans \( \R[X, Y] \):} \( P = 2X^2 + 3XY - Y \)
   \item \textbf{Dans \( \C[X, Y, Z] \):} \( P = iX^2Y^2 + 2iX - 5Z \)
\end{itemize}
\subsection*{\subsecstyle{Relations coefficients racines {:}}}
On peut trouver une relation entre les coefficients et les racines d'un polynôme qui peut souvent nous permettre de nous ramener à la résolution d'un système et potentiellement trouver les racines, en effet on suppose la décomposition acquise alors on a:
\[ 
   P = \sum_{k=0}^n a_kX^k = a_n(X - \alpha_1) \ldots (X - \alpha_n)
\]
En développant on trouve alors des relations pour la somme, la somme des doubles produits, la somme des triples produits, etc, et le produit des racines:
\begin{itemize}
   \item \textbf{La somme des racines: } \(\sum_{1 \leq i \leq n} \alpha_i = (-1)^1 \frac{a_{n-1}}{a_n} \)
   \item \textbf{La somme des k-produits des racines: } \( \sum_{1 \leq i_1 < \ldots < i_k \leq n} \alpha_{i_1} \ldots \alpha_{i_k} = (-1)^k \frac{a_{n-k}}{a_n} \)
   \item \textbf{Le produit des racines: } \(\alpha_1 \ldots \alpha_n = (-1)^n \frac{a_0}{a_n} \)
\end{itemize}